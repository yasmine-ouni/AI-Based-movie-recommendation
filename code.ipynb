{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\msi\\lib\\site-packages (0.5.15)\n",
      "Requirement already satisfied: langchain in c:\\users\\msi\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: transformers in c:\\users\\msi\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\msi\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\msi\\lib\\site-packages (from chromadb) (2.8.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.115.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\msi\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\msi\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\msi\\lib\\site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (1.67.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\msi\\lib\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\msi\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\msi\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\msi\\lib\\site-packages (from chromadb) (3.10.6)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\msi\\lib\\site-packages (from chromadb) (13.9.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\msi\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\msi\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\msi\\lib\\site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\msi\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\msi\\lib\\site-packages (from langchain) (0.1.140)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\msi\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\msi\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\msi\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\msi\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\msi\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in c:\\users\\msi\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.40.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\msi\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\msi\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\msi\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\msi\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\msi\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\msi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\msi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.35.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\msi\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\msi\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\msi\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\msi\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\msi\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\msi\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\msi\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (72.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\msi\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\msi\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\msi\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\msi\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\msi\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\msi\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\msi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\msi\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\msi\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\msi\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\msi\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\msi\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\msi\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\msi\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\msi\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msi\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\msi\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\msi\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\msi\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\msi\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\msi\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\msi\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\msi\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\msi\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb langchain transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\msi\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\msi\\lib\\site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\msi\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\msi\\lib\\site-packages (0.3.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (0.1.140)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\msi\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\msi\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\msi\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\msi\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\msi\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\msi\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\msi\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\msi\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\msi\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\msi\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\msi\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\msi\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\msi\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\msi\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\msi\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\msi\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\msi\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\msi\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\msi\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\msi\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\msi\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\msi\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\msi\\lib\\site-packages (from plotly) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\msi\\lib\\site-packages (from plotly) (24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loader and Vector store using Langchain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ts300399</td>\n",
       "      <td>Five Came Back: The Reference Films</td>\n",
       "      <td>SHOW</td>\n",
       "      <td>This collection includes 12 World War II-era p...</td>\n",
       "      <td>1945</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>51</td>\n",
       "      <td>['documentation']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>A mentally unstable Vietnam War veteran works ...</td>\n",
       "      <td>1976</td>\n",
       "      <td>R</td>\n",
       "      <td>114</td>\n",
       "      <td>['drama', 'crime']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0075314</td>\n",
       "      <td>8.2</td>\n",
       "      <td>808582.0</td>\n",
       "      <td>40.965</td>\n",
       "      <td>8.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tm154986</td>\n",
       "      <td>Deliverance</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Intent on seeing the Cahulawassee River before...</td>\n",
       "      <td>1972</td>\n",
       "      <td>R</td>\n",
       "      <td>109</td>\n",
       "      <td>['drama', 'action', 'thriller', 'european']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0068473</td>\n",
       "      <td>7.7</td>\n",
       "      <td>107673.0</td>\n",
       "      <td>10.010</td>\n",
       "      <td>7.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm127384</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>King Arthur, accompanied by his squire, recrui...</td>\n",
       "      <td>1975</td>\n",
       "      <td>PG</td>\n",
       "      <td>91</td>\n",
       "      <td>['fantasy', 'action', 'comedy']</td>\n",
       "      <td>['GB']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0071853</td>\n",
       "      <td>8.2</td>\n",
       "      <td>534486.0</td>\n",
       "      <td>15.461</td>\n",
       "      <td>7.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm120801</td>\n",
       "      <td>The Dirty Dozen</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>12 American military prisoners in World War II...</td>\n",
       "      <td>1967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>['war', 'action']</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0061578</td>\n",
       "      <td>7.7</td>\n",
       "      <td>72662.0</td>\n",
       "      <td>20.398</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                title   type  \\\n",
       "0  ts300399  Five Came Back: The Reference Films   SHOW   \n",
       "1   tm84618                          Taxi Driver  MOVIE   \n",
       "2  tm154986                          Deliverance  MOVIE   \n",
       "3  tm127384      Monty Python and the Holy Grail  MOVIE   \n",
       "4  tm120801                      The Dirty Dozen  MOVIE   \n",
       "\n",
       "                                         description  release_year  \\\n",
       "0  This collection includes 12 World War II-era p...          1945   \n",
       "1  A mentally unstable Vietnam War veteran works ...          1976   \n",
       "2  Intent on seeing the Cahulawassee River before...          1972   \n",
       "3  King Arthur, accompanied by his squire, recrui...          1975   \n",
       "4  12 American military prisoners in World War II...          1967   \n",
       "\n",
       "  age_certification  runtime                                       genres  \\\n",
       "0             TV-MA       51                            ['documentation']   \n",
       "1                 R      114                           ['drama', 'crime']   \n",
       "2                 R      109  ['drama', 'action', 'thriller', 'european']   \n",
       "3                PG       91              ['fantasy', 'action', 'comedy']   \n",
       "4               NaN      150                            ['war', 'action']   \n",
       "\n",
       "  production_countries  seasons    imdb_id  imdb_score  imdb_votes  \\\n",
       "0               ['US']      1.0        NaN         NaN         NaN   \n",
       "1               ['US']      NaN  tt0075314         8.2    808582.0   \n",
       "2               ['US']      NaN  tt0068473         7.7    107673.0   \n",
       "3               ['GB']      NaN  tt0071853         8.2    534486.0   \n",
       "4         ['GB', 'US']      NaN  tt0061578         7.7     72662.0   \n",
       "\n",
       "   tmdb_popularity  tmdb_score  \n",
       "0            0.600         NaN  \n",
       "1           40.965       8.179  \n",
       "2           10.010       7.300  \n",
       "3           15.461       7.811  \n",
       "4           20.398       7.600  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/movie recommendation/titles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess data if necessary\n",
    "df['description'] = df['description'].fillna('')  # Fill NaN descriptions\n",
    "df = df.fillna('')\n",
    "# Clean and prepare text columns\n",
    "text_columns = ['title', 'description', 'genres']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Concatenate columns with separators for combined embedding\n",
    "df['combined_text'] = df[text_columns].agg(' | '.join, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ts300399</td>\n",
       "      <td>Five Came Back: The Reference Films</td>\n",
       "      <td>SHOW</td>\n",
       "      <td>This collection includes 12 World War II-era p...</td>\n",
       "      <td>1945</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>51</td>\n",
       "      <td>['documentation']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>A mentally unstable Vietnam War veteran works ...</td>\n",
       "      <td>1976</td>\n",
       "      <td>R</td>\n",
       "      <td>114</td>\n",
       "      <td>['drama', 'crime']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0075314</td>\n",
       "      <td>8.2</td>\n",
       "      <td>808582.0</td>\n",
       "      <td>40.965</td>\n",
       "      <td>8.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tm154986</td>\n",
       "      <td>Deliverance</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Intent on seeing the Cahulawassee River before...</td>\n",
       "      <td>1972</td>\n",
       "      <td>R</td>\n",
       "      <td>109</td>\n",
       "      <td>['drama', 'action', 'thriller', 'european']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0068473</td>\n",
       "      <td>7.7</td>\n",
       "      <td>107673.0</td>\n",
       "      <td>10.010</td>\n",
       "      <td>7.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm127384</td>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>King Arthur, accompanied by his squire, recrui...</td>\n",
       "      <td>1975</td>\n",
       "      <td>PG</td>\n",
       "      <td>91</td>\n",
       "      <td>['fantasy', 'action', 'comedy']</td>\n",
       "      <td>['GB']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0071853</td>\n",
       "      <td>8.2</td>\n",
       "      <td>534486.0</td>\n",
       "      <td>15.461</td>\n",
       "      <td>7.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm120801</td>\n",
       "      <td>The Dirty Dozen</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>12 American military prisoners in World War II...</td>\n",
       "      <td>1967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>['war', 'action']</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0061578</td>\n",
       "      <td>7.7</td>\n",
       "      <td>72662.0</td>\n",
       "      <td>20.398</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                title   type  \\\n",
       "0  ts300399  Five Came Back: The Reference Films   SHOW   \n",
       "1   tm84618                          Taxi Driver  MOVIE   \n",
       "2  tm154986                          Deliverance  MOVIE   \n",
       "3  tm127384      Monty Python and the Holy Grail  MOVIE   \n",
       "4  tm120801                      The Dirty Dozen  MOVIE   \n",
       "\n",
       "                                         description  release_year  \\\n",
       "0  This collection includes 12 World War II-era p...          1945   \n",
       "1  A mentally unstable Vietnam War veteran works ...          1976   \n",
       "2  Intent on seeing the Cahulawassee River before...          1972   \n",
       "3  King Arthur, accompanied by his squire, recrui...          1975   \n",
       "4  12 American military prisoners in World War II...          1967   \n",
       "\n",
       "  age_certification  runtime                                       genres  \\\n",
       "0             TV-MA       51                            ['documentation']   \n",
       "1                 R      114                           ['drama', 'crime']   \n",
       "2                 R      109  ['drama', 'action', 'thriller', 'european']   \n",
       "3                PG       91              ['fantasy', 'action', 'comedy']   \n",
       "4               NaN      150                            ['war', 'action']   \n",
       "\n",
       "  production_countries  seasons    imdb_id  imdb_score  imdb_votes  \\\n",
       "0               ['US']      1.0        NaN         NaN         NaN   \n",
       "1               ['US']      NaN  tt0075314         8.2    808582.0   \n",
       "2               ['US']      NaN  tt0068473         7.7    107673.0   \n",
       "3               ['GB']      NaN  tt0071853         8.2    534486.0   \n",
       "4         ['GB', 'US']      NaN  tt0061578         7.7     72662.0   \n",
       "\n",
       "   tmdb_popularity  tmdb_score  \n",
       "0            0.600         NaN  \n",
       "1           40.965       8.179  \n",
       "2           10.010       7.300  \n",
       "3           15.461       7.811  \n",
       "4           20.398       7.600  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/movie recommendation/titles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\msi\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "Model not found in cache. Downloading the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating movie recommendations...\n",
      "I want an action movie recommendation.\n",
      "\n",
      "**What kind of movies do you enjoy?**\n",
      " \n",
      "  *  Give me some details about your preferences.\n",
      "   \n",
      " **For example:** \n",
      "\n",
      "* I like **fast-paced, high-octane action with witty dialogue and compelling characters**. \n",
      "\n",
      "\n",
      "Let me know and I can give you a tailored recommendation! ðŸ¿ ðŸ’¥ ðŸŽ¥ ðŸ¦¸â€â™€ï¸\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "import os\n",
    "\n",
    "def generate_movie_recommendations(prompt, huggingface_token):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations based on the provided prompt, considering the user's preferences for genre, actors, or descriptions.\n",
    "    \n",
    "    Args:\n",
    "    - prompt (str): The input text from the user, describing their preferences (e.g., genre, actor, mood).\n",
    "    - huggingface_token (str): Hugging Face authentication token.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The generated response with movie recommendations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Login to Hugging Face Hub\n",
    "    login(huggingface_token)\n",
    "    \n",
    "    model_name = \"google/gemma-2-2b-it\"  # Model you want to use\n",
    "    \n",
    "    # Define the path to the model's cache\n",
    "    model_cache_dir = os.path.join(os.path.expanduser(\"~\"), \".cache\", \"huggingface\", \"transformers\", model_name)\n",
    "\n",
    "    # Check if model is already downloaded\n",
    "    if os.path.isdir(model_cache_dir):\n",
    "        print(\"Model is already downloaded. Loading from cache.\")\n",
    "    else:\n",
    "        print(\"Model not found in cache. Downloading the model.\")\n",
    "        # Download model weights and tokenizer explicitly without 'use_tqdm' argument\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=huggingface_token)\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=huggingface_token)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading model or tokenizer: {str(e)}\")\n",
    "    \n",
    "    # Move model to the appropriate device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate the output using the model\n",
    "    print(\"Generating movie recommendations...\")\n",
    "    try:\n",
    "        # Generate the movie recommendation with do_sample=True\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                inputs['input_ids'], \n",
    "                max_length=250, \n",
    "                num_return_sequences=1,\n",
    "                no_repeat_ngram_size=2,  # Prevent repetition of ngrams\n",
    "                top_k=50,                # Top-K sampling for diversity\n",
    "                top_p=0.95,              # Top-p (nucleus) sampling\n",
    "                temperature=0.7,         # Temperature controls the randomness of the output\n",
    "                do_sample=True           # Enable sampling so that temperature and top_p can be used\n",
    "            )\n",
    "\n",
    "        # Decode the generated output\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error during text generation: {str(e)}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "huggingface_token = \"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\"  # Replace with your Hugging Face token\n",
    "prompt = \"I want an action movie recommendation.\"\n",
    "\n",
    "response = generate_movie_recommendations(prompt, huggingface_token)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 0.5/1.7 MB 148.5 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 0.8/1.7 MB 151.8 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 0.8/1.7 MB 151.8 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 0.8/1.7 MB 151.8 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 0.8/1.7 MB 151.8 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.0/1.7 MB 185.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 1.3/1.7 MB 144.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.6/1.7 MB 114.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 1.7/1.7 MB 111.7 kB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.6.0\n",
      "    Uninstalling keras-3.6.0:\n",
      "      Successfully uninstalled keras-3.6.0\n",
      "Successfully installed keras-2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires keras>=3.5.0, but you have keras 2.13.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.13.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\msi\\lib\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\msi\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['id', 'title', 'type', 'description', 'release_year', 'age_certification', 'runtime', 'genres', 'production_countries', 'seasons', 'imdb_id', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score', 'combined_features']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in DataFrame:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Perform EDA on the DataFrame and handle missing values\n",
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Perform Exploratory Data Analysis on the DataFrame and handle missing values.\n",
    "    \"\"\"\n",
    "    # Handling missing values based on column types\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numerical_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            # Fill missing values with median if data is skewed; otherwise, use mean\n",
    "            fill_value = df[col].median() if df[col].skew() > 1 else df[col].mean()\n",
    "            df[col] = df[col].fillna(fill_value)  # Updated to assignment\n",
    "    \n",
    "    # For categorical columns, fill missing values with a placeholder 'NaN' or 'Unknown'\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna('NaN')  # Updated to assignment\n",
    "    \n",
    "    # Drop duplicates if any based on 'id' column\n",
    "    df = df.drop_duplicates(subset='id', keep='first')\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('D:/movie recommendation/titles.csv')\n",
    "df = perform_eda(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\msi\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up Hugging Face authentication using your token\n",
    "hf_token = \"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\"  # Replace with your Hugging Face token\n",
    "login(token=hf_token)  # Log in to Hugging Face account\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Initialize Chroma DB and add movie embeddings for retrieval\n",
    "def initialize_chroma_db(df, batch_size=500):\n",
    "    \"\"\"\n",
    "    Initialize Chroma DB and add movie embeddings for retrieval.\n",
    "    Add data in batches to avoid exceeding the max batch size.\n",
    "    \"\"\"\n",
    "    client = chromadb.Client()\n",
    "    collection_name = \"movies_collection\"\n",
    "    \n",
    "    # Check if collection exists; if not, create it\n",
    "    try:\n",
    "        collection = client.get_collection(collection_name)\n",
    "    except chromadb.errors.InvalidCollectionException:\n",
    "        collection = client.create_collection(collection_name)\n",
    "    \n",
    "    sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    def combine_features(row):\n",
    "        description = row['description'] if pd.notnull(row['description']) else 'No description available'\n",
    "        genres = ', '.join(row['genres']) if isinstance(row['genres'], list) else (row['genres'] if pd.notnull(row['genres']) else 'Unknown genres')\n",
    "        imdb_score = row['imdb_score'] if pd.notnull(row['imdb_score']) else 'Unknown'\n",
    "        release_year = row['release_year'] if pd.notnull(row['release_year']) else 'Unknown'\n",
    "        return f\"{description} | Genres: {genres} | IMDb Score: {imdb_score} | Release Year: {release_year}\"\n",
    "\n",
    "    # Handle missing values in 'title' and 'combined_features' columns\n",
    "    df['title'] = df['title'].fillna(\"unknown\")\n",
    "    df['combined_features'] = df.apply(combine_features, axis=1)\n",
    "    df = df.drop_duplicates(subset='id', keep='first')\n",
    "\n",
    "    # Generate embeddings for combined features\n",
    "    embeddings = [sentence_model.encode(text).tolist() for text in df['combined_features']]\n",
    "\n",
    "    # Ensure unique IDs by appending an index to duplicates\n",
    "    id_counts = {}\n",
    "    ids = []\n",
    "    for title in df['title']:\n",
    "        title_key = str(title).replace(\" \", \"_\").lower()\n",
    "        if title_key in id_counts:\n",
    "            id_counts[title_key] += 1\n",
    "            unique_id = f\"{title_key}_{id_counts[title_key]}\"\n",
    "        else:\n",
    "            id_counts[title_key] = 1\n",
    "            unique_id = f\"{title_key}_1\"\n",
    "        ids.append(unique_id)\n",
    "\n",
    "    # Split data into smaller batches and add to the collection\n",
    "    for i in range(0, len(ids), batch_size):\n",
    "        batch_ids = ids[i:i+batch_size]\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_metadatas = df[['title', 'description', 'genres', 'imdb_score', 'release_year']].iloc[i:i+batch_size].to_dict(orient='records')\n",
    "        batch_documents = df['combined_features'].iloc[i:i+batch_size].tolist()\n",
    "\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            documents=batch_documents,\n",
    "            metadatas=batch_metadatas,\n",
    "            embeddings=batch_embeddings\n",
    "        )\n",
    "    \n",
    "    return client, collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma DB with batch size to avoid exceeding limits\n",
    "client, collection = initialize_chroma_db(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Retrieve the most relevant movies from Chroma DB based on user input\n",
    "def get_relevant_movies(user_input, collection, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve the top-k most relevant movie recommendations from the Chroma collection.\n",
    "    \"\"\"\n",
    "    # Use the user's input to query the Chroma collection\n",
    "    results = collection.query(query_texts=[user_input], n_results=top_k)\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    recommendations = pd.DataFrame(results['documents'])\n",
    "    \n",
    "    # Inspect the columns and adjust based on the actual structure\n",
    "    print(\"Results from Chroma:\", recommendations.head())  # Inspect the output\n",
    "    \n",
    "    # Check the number of columns in recommendations and adjust accordingly\n",
    "    num_columns = recommendations.shape[1]\n",
    "    \n",
    "    if num_columns == 1:\n",
    "        # If there is only one column (combined features), we assume it's a combined string\n",
    "        recommendations.columns = ['combined_features']\n",
    "        \n",
    "        # Now, split and expand the relevant information from 'combined_features'\n",
    "        recommendations[['description', 'genres', 'imdb_score', 'release_year']] = recommendations['combined_features'].str.split('|', expand=True)\n",
    "        recommendations[['genres', 'imdb_score', 'release_year']] = recommendations[['genres', 'imdb_score', 'release_year']].apply(lambda x: x.str.split(':').str[1].str.strip())\n",
    "\n",
    "        # Extract the title if needed (this assumes the title can be separated from the rest)\n",
    "        recommendations['title'] = recommendations['combined_features'].str.split('|').str[0]\n",
    "        \n",
    "        # Filter and select the relevant columns for the final output\n",
    "        recommendations = recommendations[['title', 'description', 'genres', 'imdb_score', 'release_year']]\n",
    "    \n",
    "    elif num_columns >= 5:\n",
    "        # If there are multiple columns, we assume the columns already represent relevant information\n",
    "        # You can adjust this logic based on the actual structure of your Chroma output\n",
    "        recommendations.columns = ['title', 'description', 'genres', 'imdb_score', 'release_year']\n",
    "    \n",
    "    else:\n",
    "        # If there is an unexpected number of columns, print and inspect the result\n",
    "        print(f\"Unexpected number of columns: {num_columns}\")\n",
    "        print(recommendations.head())\n",
    "        return None\n",
    "    \n",
    "    # Now, you can return the relevant movie information\n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate the final response with the recommended movies using RAG\n",
    "def generate_response(user_input, collection, top_k=5):\n",
    "    \"\"\"\n",
    "    Generate a response using RAG (Retrieval-Augmented Generation) with the top-k relevant movie context.\n",
    "    \"\"\"\n",
    "    # Get the top-k relevant movie recommendations\n",
    "    context = get_relevant_movies(user_input, collection, top_k)\n",
    "    \n",
    "    # Format the context to include movie information\n",
    "    context_str = \"\\n\".join([ \n",
    "        f\"Movie: {row['title']} | Genres: {row['genres']} | IMDb Score: {row['imdb_score']} | Release Year: {row['release_year']}\\nDescription: {row['description']}\" \n",
    "        for _, row in context.iterrows()\n",
    "    ])\n",
    "    \n",
    "    # Create the final prompt for the model\n",
    "    final_prompt = f\"User Query: {user_input}\\n\\nHere are some movie recommendations based on your request:\\n{context_str}\\n\\nProvide me with the best recommendation.\"\n",
    "\n",
    "    # Initialize the model and tokenizer\n",
    "    model_name = \"google/gemma-2-2b-it\"\n",
    "\n",
    "    # Step 6: Fix model cache path issue based on platform (Windows/Unix)\n",
    "    def get_model_cache_path(model_name):\n",
    "        home_dir = os.getenv('USERPROFILE') or os.getenv('HOME')\n",
    "        if home_dir is None:\n",
    "            raise EnvironmentError(\"HOME or USERPROFILE environment variable is not set.\")\n",
    "        return os.path.join(home_dir, '.cache', 'huggingface', 'transformers', model_name.replace('/', '_'))\n",
    "\n",
    "    model_cache_path = get_model_cache_path(model_name)\n",
    "    \n",
    "    # Check if model is already downloaded\n",
    "    if os.path.exists(model_cache_path):\n",
    "        print(f\"Model {model_name} already downloaded.\")\n",
    "    else:\n",
    "        print(f\"Downloading {model_name}...\")\n",
    "\n",
    "    # Use Hugging Face token for authentication\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token, torch_dtype=torch.float16)\n",
    "\n",
    "    \n",
    "    # Set the device for model inference\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(final_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # Generate the response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            max_length=350, \n",
    "            num_return_sequences=1, \n",
    "            no_repeat_ngram_size=2, \n",
    "            top_k=50, \n",
    "            top_p=0.95, \n",
    "            temperature=0.7, \n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    # Decode the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I want an horror movie\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "response = generate_response(user_input, collection)\n",
    "print(\"Generated response:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
